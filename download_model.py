#!/usr/bin/env python3
"""
Download MedSigLIP-448 model to local cache
Run this once to avoid downloading during training
"""

import os
import sys
from pathlib import Path

# Load environment variables
try:
    from dotenv import load_dotenv
    load_dotenv()
    print("‚úÖ Environment variables loaded from .env file")
except ImportError:
    print("‚ùå Error: python-dotenv not found. Install with: pip install python-dotenv")
    sys.exit(1)

# Check HuggingFace token
hf_token = os.getenv("HUGGINGFACE_TOKEN")
if not hf_token:
    print("‚ùå Error: HUGGINGFACE_TOKEN not found in .env file")
    print("Add: HUGGINGFACE_TOKEN=hf_your_token_here")
    sys.exit(1)

# Setup cache directory
results_dir = Path("results")
models_dir = results_dir / "models"
models_dir.mkdir(parents=True, exist_ok=True)

# Set transformers cache
os.environ["TRANSFORMERS_CACHE"] = str(models_dir)

print("üè• MEDSIGLIP-448 MODEL DOWNLOADER")
print("="*50)
print(f"üì• Downloading MedSigLIP-448 model...")
print(f"üíæ Cache location: {models_dir}")
print(f"üîó Model: google/medsiglip-448")
print("")

try:
    from transformers import AutoModel
    
    # Download the model
    print("‚è¨ Starting download...")
    model = AutoModel.from_pretrained(
        "google/medsiglip-448",
        token=hf_token,
        trust_remote_code=True,
        cache_dir=str(models_dir)
    )
    
    print("")
    print("‚úÖ SUCCESS: MedSigLIP-448 model downloaded successfully!")
    print(f"üíæ Cached at: {models_dir}")
    print("")
    print("üöÄ NEXT STEPS:")
    print("  ‚Ä¢ Model is now cached locally")
    print("  ‚Ä¢ Training will start instantly (no download)")
    print("  ‚Ä¢ Run: ./mlx_train_local.sh")
    print("")
    
except Exception as e:
    print(f"‚ùå ERROR: Failed to download model: {e}")
    print("")
    print("üîß TROUBLESHOOTING:")
    print("  ‚Ä¢ Check your HUGGINGFACE_TOKEN in .env file")
    print("  ‚Ä¢ Ensure token has access to google/medsiglip-448")
    print("  ‚Ä¢ Check internet connection")
    sys.exit(1)