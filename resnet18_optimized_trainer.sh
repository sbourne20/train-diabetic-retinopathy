#!/bin/bash

# ResNet18 Optimized Training Script - Smaller Architecture for Better Generalization
# After ResNet50 consistent overfitting, switching to ResNet18 (11M vs 23.5M parameters)
# Balanced regularization settings optimized for smaller model capacity

echo "ğŸ—ï¸ RESNET18 OPTIMIZED TRAINING"
echo "Strategy: Smaller architecture for better generalization"
echo "ResNet18: 11M parameters vs ResNet50: 23.5M parameters (53% reduction)"
echo "Goal: Stable training with >79.56% validation accuracy"
echo ""

# Check if dataset exists
if [ ! -d "./dataset5" ]; then
    echo "âŒ ERROR: Dataset directory './dataset5' not found"
    echo "Please ensure the dataset is available in the current directory"
    exit 1
fi

# Remove any existing ResNet checkpoints to start fresh
echo "ğŸ§¹ Cleaning previous ResNet checkpoints..."
rm -f ./results/checkpoints/best_resnet*.pth
rm -f ./results/checkpoints/resnet*_epoch_*.pth
echo "âœ… Previous ResNet checkpoints removed"

echo "ğŸ¯ RESNET18 ARCHITECTURE ADVANTAGES:"
echo "  ğŸ“Š Parameters: 11M (vs ResNet50: 23.5M)"
echo "  ğŸ›¡ï¸ Reduced overfitting risk due to smaller capacity"
echo "  âš¡ Faster training and inference"
echo "  ğŸ¯ Better suited for medical imaging dataset size"
echo "  ğŸ“ˆ Historical success with medical image classification"
echo ""

echo "âš–ï¸ BALANCED REGULARIZATION SETTINGS:"
echo "  ğŸ¯ Learning Rate: 2e-5 (conservative but not extreme)"
echo "  ğŸ›¡ï¸ Dropout: 0.35 + 0.25 (dual dropout, moderate)"
echo "  âš–ï¸ Weight Decay: 1e-3 (standard regularization)"
echo "  ğŸ›‘ Early Stopping: 7 epochs patience (reasonable)"
echo "  ğŸ“Š Min Delta: 0.005 (balanced improvement threshold)"
echo "  ğŸ­ Label Smoothing: 0.2 (prevent overconfidence)"
echo "  ğŸ—ï¸ Architecture: Dual FC layers (256 intermediate)"
echo ""

echo "ğŸ“š STRATEGY RATIONALE:"
echo "  â€¢ Smaller model = less prone to memorization"
echo "  â€¢ Balanced regularization = avoid underfitting"
echo "  â€¢ Allow model capacity to match dataset complexity"
echo "  â€¢ Focus on stable generalization over speed"
echo ""

echo "ğŸ¥ MEDICAL-GRADE CONFIGURATION:"
echo "  âœ… CLAHE preprocessing enabled"
echo "  âœ… SMOTE class balancing enabled"
echo "  âœ… Focal loss for imbalanced classes"
echo "  âœ… Class weights optimization"
echo "  âœ… Medical-grade validation thresholds"
echo ""

echo "ğŸ”§ RESNET18 TRAINING PARAMETERS:"
echo "  ğŸ—ï¸  Architecture: ResNet18 (pre-trained) + Dual FC"
echo "  ğŸ“Š Epochs: 100 (with balanced early stopping)"
echo "  ğŸ¯ Target accuracy: >79.56% (beat EfficientNetB2)"
echo "  ğŸ¥ Medical threshold: â‰¥90%"
echo "  ğŸ“ˆ Validation frequency: Every epoch"
echo "  ğŸ’¾ Checkpoint frequency: Every 5 epochs"
echo "  ğŸ“¦ Batch size: 6 (optimized for V100)"
echo "  ğŸ›¡ï¸ Overfitting protection: BALANCED"
echo ""

echo "ğŸ“ˆ EXPECTED TRAINING PATTERN:"
echo "  â€¢ Steady learning without rapid spikes"
echo "  â€¢ Train-val gap should stay <12% throughout"
echo "  â€¢ Convergence in 20-40 epochs (reasonable time)"
echo "  â€¢ Stable validation improvement without decline"
echo ""

echo "ğŸš€ Starting ResNet18 optimized training..."
echo "=========================================="

# Ensure output directory structure exists
echo "ğŸ“ Creating ResNet18 output directories..."
mkdir -p ./results
mkdir -p ./results/checkpoints
mkdir -p ./results/logs
mkdir -p ./results/resnet18
echo "âœ… Output directories created: $(pwd)/results"

python individual_model_trainer.py \
    --model resnet18 \
    --dataset_path ./dataset5 \
    --output_dir ./results \
    --epochs 100 \
    --batch_size 6 \
    --gradient_accumulation_steps 2 \
    --learning_rate 2e-5 \
    --weight_decay 1e-3 \
    --dropout 0.5 \
    --max_grad_norm 0.5 \
    --patience 7 \
    --min_delta 0.005 \
    --scheduler cosine \
    --warmup_epochs 5 \
    --enable_clahe \
    --enable_smote \
    --enable_focal_loss \
    --enable_class_weights \
    --validation_frequency 1 \
    --checkpoint_frequency 5 \
    --medical_terms data/medical_terms_type1.json \
    --experiment_name resnet18_optimized_balanced_regularization

EXIT_CODE=$?

echo ""
echo "=========================================="
if [ $EXIT_CODE -eq 0 ]; then
    echo "âœ… ResNet18 optimized training completed!"
    echo "ğŸ¯ Check results in ./results/ directory"
    echo ""
    echo "ğŸ“ ResNet18 checkpoint verification:"
    if [ -f "./results/checkpoints/best_resnet18.pth" ]; then
        echo "   âœ… ResNet18 model saved: best_resnet18.pth"

        # Use model analyzer to check performance and overfitting
        if [ -f "model_analyzer.py" ]; then
            echo ""
            echo "ğŸ“Š Running comprehensive model analysis..."
            python model_analyzer.py --model ./results/checkpoints/best_resnet18.pth --verbose
        fi
    else
        echo "   âŒ ResNet18 checkpoint not found"
    fi

    echo ""
    echo "ğŸ¯ GENERALIZATION SUCCESS METRICS:"
    echo "   âœ… Target: Train-Val gap <12% throughout training"
    echo "   âœ… Target: Validation accuracy >79.56%"
    echo "   âœ… Target: Stable convergence without memorization"
    echo "   âœ… Target: No severe overfitting patterns"
    echo ""
    echo "ğŸ¯ PERFORMANCE COMPARISON:"
    echo "   EfficientNetB2: 79.56% (baseline to beat)"
    echo "   ResNet50 (multiple attempts): ~72-73% (overfitted consistently)"
    echo "   ResNet18 (optimized): $([ -f "./results/checkpoints/best_resnet18.pth" ] && echo "CHECK ANALYSIS ABOVE" || echo "TRAINING FAILED")"
    echo ""
    echo "ğŸ¯ ENSEMBLE PROGRESS:"
    echo "   Phase 1: EfficientNetB2 $([ -f "./results/checkpoints/best_efficientnetb2.pth" ] && echo "âœ… (79.56%)" || echo "âŒ")"
    echo "   Phase 2: ResNet18 $([ -f "./results/checkpoints/best_resnet18.pth" ] && echo "âœ… (OPTIMIZED)" || echo "âŒ")"
    echo "   Phase 3: DenseNet121 â³ (Next: apply balanced approach)"
    echo ""
    echo "ğŸ“‹ NEXT STEPS:"
    if [ -f "./results/checkpoints/best_resnet18.pth" ]; then
        echo "   1. âœ… Analyze ResNet18 performance vs EfficientNetB2"
        echo "   2. If >79.56%, proceed to DenseNet121 with similar settings"
        echo "   3. If still overfitting, consider even smaller architecture"
        echo "   4. Create ensemble with best available models"
    else
        echo "   1. âŒ Review training logs for issues"
        echo "   2. Consider further architectural adjustments"
        echo "   3. Alternative: Use EfficientNetB2 as primary model"
    fi

else
    echo "âŒ ResNet18 optimized training failed with exit code: $EXIT_CODE"
    echo "ğŸ” Check logs above for error details"
    echo ""
    echo "ğŸ’¡ Troubleshooting suggestions:"
    echo "   1. Check GPU memory with ResNet18 architecture"
    echo "   2. Verify dataset compatibility"
    echo "   3. Review model initialization parameters"
    echo "   4. Consider batch size adjustments"
    echo ""
    echo "ğŸ”„ Alternative approaches:"
    echo "   1. Try different learning rate (1e-5 or 5e-5)"
    echo "   2. Adjust dropout rates (0.3-0.6 range)"
    echo "   3. Use simpler architecture (e.g., ResNet34)"
fi

exit $EXIT_CODE