#!/bin/bash

# ResNet50 Ultra-Conservative Anti-Overfitting Training Script
# Maximum regularization settings to prevent overfitting at all costs
# Based on analysis: Previous attempts overfitted despite aggressive settings

echo "ğŸ›¡ï¸ RESNET50 ULTRA-CONSERVATIVE TRAINING"
echo "Previous attempts: 79.56% (EfficientNet) vs 72.73% (ResNet50 overfitted)"
echo "Ultra-aggressive regularization: Maximum dropout, minimum learning rate"
echo "Goal: Stable generalization even if slower convergence"
echo ""

# Check if dataset exists
if [ ! -d "./dataset5" ]; then
    echo "âŒ ERROR: Dataset directory './dataset5' not found"
    echo "Please ensure the dataset is available in the current directory"
    exit 1
fi

# Remove previous ResNet50 checkpoints to start fresh
echo "ğŸ§¹ Cleaning previous ResNet50 checkpoints..."
rm -f ./results/checkpoints/best_resnet50.pth
rm -f ./results/checkpoints/resnet50_epoch_*.pth
echo "âœ… Previous ResNet50 checkpoints removed"

echo "ğŸ›¡ï¸ ULTRA-CONSERVATIVE ANTI-OVERFITTING SETTINGS:"
echo "  ğŸŒ Learning Rate: 1e-5 (extremely slow - 5x reduction)"
echo "  ğŸ›¡ï¸ Dropout: 0.7 + 0.56 (dual dropout layers - maximum regularization)"
echo "  âš–ï¸ Weight Decay: 5e-3 (5x stronger regularization)"
echo "  ğŸ›‘ Early Stopping: 3 epochs patience (immediate stop)"
echo "  ğŸ“Š Min Delta: 0.01 (requires significant improvement)"
echo "  ğŸ­ Label Smoothing: 0.2 (maximum uncertainty injection)"
echo "  âœ‚ï¸ Gradient Clipping: 0.5 (strict gradient control)"
echo "  ğŸ—ï¸ Architecture: Dual FC layers with heavy dropout"
echo ""

echo "ğŸ“š THEORETICAL APPROACH:"
echo "  â€¢ Sacrifice training speed for generalization stability"
echo "  â€¢ Force model to learn robust patterns, not memorize"
echo "  â€¢ Stop immediately if validation doesn't improve"
echo "  â€¢ Accept slower convergence to prevent overfitting"
echo ""

echo "ğŸ¥ MEDICAL-GRADE CONFIGURATION:"
echo "  âœ… CLAHE preprocessing enabled"
echo "  âœ… SMOTE class balancing enabled"
echo "  âœ… Focal loss for imbalanced classes"
echo "  âœ… Class weights optimization"
echo "  âœ… Medical-grade validation thresholds"
echo ""

echo "ğŸ”§ ULTRA-CONSERVATIVE TRAINING PARAMETERS:"
echo "  ğŸ—ï¸  Architecture: ResNet50 (pre-trained) + Dual FC"
echo "  ğŸ“Š Epochs: 100 (with aggressive early stopping)"
echo "  ğŸ¯ Target accuracy: >79.56% (beat EfficientNetB2)"
echo "  ğŸ¥ Medical threshold: â‰¥90%"
echo "  ğŸ“ˆ Validation frequency: Every epoch"
echo "  ğŸ’¾ Checkpoint frequency: Every 5 epochs"
echo "  ğŸ“¦ Batch size: 6 (optimized for V100)"
echo "  ğŸ›¡ï¸ Overfitting protection: MAXIMUM"
echo ""

echo "âš ï¸ EXPECTED BEHAVIOR:"
echo "  â€¢ Very slow initial learning (by design)"
echo "  â€¢ Train-val gap should stay <10% throughout"
echo "  â€¢ May stop early (3-15 epochs) if no improvement"
echo "  â€¢ Quality over speed - stable generalization priority"
echo ""

echo "ğŸš€ Starting ResNet50 ultra-conservative training..."
echo "=========================================="

# Ensure output directory structure exists
echo "ğŸ“ Creating ResNet50 output directories..."
mkdir -p ./results
mkdir -p ./results/checkpoints
mkdir -p ./results/logs
mkdir -p ./results/resnet50
echo "âœ… Output directories created: $(pwd)/results"

python individual_model_trainer.py \
    --model resnet50 \
    --dataset_path ./dataset5 \
    --output_dir ./results \
    --epochs 100 \
    --batch_size 6 \
    --gradient_accumulation_steps 2 \
    --learning_rate 1e-5 \
    --weight_decay 5e-3 \
    --dropout 0.7 \
    --max_grad_norm 0.5 \
    --patience 3 \
    --min_delta 0.01 \
    --scheduler plateau \
    --warmup_epochs 5 \
    --enable_clahe \
    --enable_smote \
    --enable_focal_loss \
    --enable_class_weights \
    --validation_frequency 1 \
    --checkpoint_frequency 5 \
    --medical_terms data/medical_terms_type1.json \
    --experiment_name resnet50_ultra_conservative_max_regularization

EXIT_CODE=$?

echo ""
echo "=========================================="
if [ $EXIT_CODE -eq 0 ]; then
    echo "âœ… ResNet50 ultra-conservative training completed!"
    echo "ğŸ¯ Check results in ./results/ directory"
    echo ""
    echo "ğŸ“ ResNet50 checkpoint verification:"
    if [ -f "./results/checkpoints/best_resnet50.pth" ]; then
        echo "   âœ… ResNet50 model saved: best_resnet50.pth"

        # Use model analyzer to check performance and overfitting
        if [ -f "model_analyzer.py" ]; then
            echo ""
            echo "ğŸ“Š Running comprehensive model analysis..."
            python model_analyzer.py --model ./results/checkpoints/best_resnet50.pth --verbose
        fi
    else
        echo "   âŒ ResNet50 checkpoint not found"
    fi

    echo ""
    echo "ğŸ¯ ANTI-OVERFITTING SUCCESS METRICS:"
    echo "   âœ… Target: Train-Val gap <15% throughout training"
    echo "   âœ… Target: Validation accuracy >79.56%"
    echo "   âœ… Target: No declining validation accuracy pattern"
    echo "   âœ… Target: Stable convergence without memorization"
    echo ""
    echo "ğŸ¯ PERFORMANCE COMPARISON:"
    echo "   EfficientNetB2: 79.56% (baseline to beat)"
    echo "   ResNet50 (1st): 73.44% (overfitted at epoch 11)"
    echo "   ResNet50 (2nd): 72.73% (overfitted at epoch 7)"
    echo "   ResNet50 (3rd): $([ -f "./results/checkpoints/best_resnet50.pth" ] && echo "CHECK ANALYSIS ABOVE" || echo "TRAINING FAILED")"
    echo ""
    echo "ğŸ¯ ENSEMBLE PROGRESS:"
    echo "   Phase 1: EfficientNetB2 $([ -f "./results/checkpoints/best_efficientnetb2.pth" ] && echo "âœ… (79.56%)" || echo "âŒ")"
    echo "   Phase 2: ResNet50 $([ -f "./results/checkpoints/best_resnet50.pth" ] && echo "âœ… (ULTRA-CONSERVATIVE)" || echo "âŒ")"
    echo "   Phase 3: DenseNet121 â³ (Next: apply same ultra-conservative approach)"
    echo ""
    echo "ğŸ“‹ NEXT STEPS:"
    if [ -f "./results/checkpoints/best_resnet50.pth" ]; then
        echo "   1. Analyze train-val gap from model analyzer"
        echo "   2. If successful (>79.56%), proceed to DenseNet121"
        echo "   3. Apply same ultra-conservative settings to DenseNet121"
        echo "   4. Create ensemble with all three models"
    else
        echo "   1. Review training logs for early stopping trigger"
        echo "   2. Consider if even more conservative settings needed"
        echo "   3. Alternative: Accept current best models and create ensemble"
    fi

else
    echo "âŒ ResNet50 ultra-conservative training failed with exit code: $EXIT_CODE"
    echo "ğŸ” Check logs above for error details"
    echo ""
    echo "ğŸ’¡ Analysis suggestions:"
    echo "   1. Check if early stopping triggered too quickly"
    echo "   2. Verify GPU memory with ultra-regularized model"
    echo "   3. Review if learning rate is too low for convergence"
    echo "   4. Consider batch size adjustment for stability"
    echo ""
    echo "ğŸ”„ Fallback options:"
    echo "   1. Use best existing model (EfficientNetB2: 79.56%)"
    echo "   2. Proceed to DenseNet121 with current settings"
    echo "   3. Create ensemble with available models"
fi

exit $EXIT_CODE