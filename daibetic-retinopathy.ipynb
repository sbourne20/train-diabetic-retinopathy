{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":4104,"databundleVersionId":46661,"sourceType":"competition"},{"sourceId":14774,"databundleVersionId":875431,"sourceType":"competition"}],"dockerImageVersionId":30840,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## IMPORTING LIBRARIES","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport cv2\nimport os\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tqdm import tqdm\nimport seaborn as sns\nfrom sklearn.metrics import confusion_matrix","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T08:32:13.655922Z","iopub.execute_input":"2025-09-26T08:32:13.656233Z","iopub.status.idle":"2025-09-26T08:32:26.833756Z","shell.execute_reply.started":"2025-09-26T08:32:13.656173Z","shell.execute_reply":"2025-09-26T08:32:26.833019Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"Num GPUs Available:\", len(tf.config.experimental.list_physical_devices('GPU')))\ntf.config.experimental.set_memory_growth(tf.config.experimental.list_physical_devices('GPU')[0], True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T08:32:26.83464Z","iopub.execute_input":"2025-09-26T08:32:26.83513Z","iopub.status.idle":"2025-09-26T08:32:27.375577Z","shell.execute_reply.started":"2025-09-26T08:32:26.835105Z","shell.execute_reply":"2025-09-26T08:32:27.374598Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## LOADING DATA","metadata":{}},{"cell_type":"code","source":"img_size = 224\nbatch_size = 32\ncsv_path = \"/kaggle/input/aptos2019-blindness-detection/train.csv\"\nimg_dir = \"/kaggle/input/aptos2019-blindness-detection/train_images\"\nsave_dir = \"/kaggle/working/preprocessed_images\" #to save preprocessed images","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T08:32:27.376553Z","iopub.execute_input":"2025-09-26T08:32:27.376876Z","iopub.status.idle":"2025-09-26T08:32:27.424479Z","shell.execute_reply.started":"2025-09-26T08:32:27.376837Z","shell.execute_reply":"2025-09-26T08:32:27.423419Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"os.makedirs(save_dir, exist_ok=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T08:32:27.425453Z","iopub.execute_input":"2025-09-26T08:32:27.425772Z","iopub.status.idle":"2025-09-26T08:32:27.439674Z","shell.execute_reply.started":"2025-09-26T08:32:27.425745Z","shell.execute_reply":"2025-09-26T08:32:27.438678Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df = pd.read_csv(csv_path)\ndf[\"id_code\"] = df[\"id_code\"].apply(lambda x: os.path.join(img_dir, x + \".png\"))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T08:32:27.44058Z","iopub.execute_input":"2025-09-26T08:32:27.440829Z","iopub.status.idle":"2025-09-26T08:32:27.477763Z","shell.execute_reply.started":"2025-09-26T08:32:27.440804Z","shell.execute_reply":"2025-09-26T08:32:27.47705Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## CLACHE PREPROCESSING","metadata":{}},{"cell_type":"code","source":"def apply_clahe_and_save(image_path, save_dir):\n    # Read and resize the image\n    image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n    if image is None:\n        raise ValueError(f\"Unable to read image at path: {image_path}\")\n    image = cv2.resize(image, (img_size, img_size))\n    \n    # Convert to LAB color space\n    lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n    l, a, b = cv2.split(lab)\n    \n    # Apply CLAHE to the L channel\n    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n    cl = clahe.apply(l)\n    \n    # Merge the LAB channels and convert back to RGB\n    merged_lab = cv2.merge((cl, a, b))\n    final_image = cv2.cvtColor(merged_lab, cv2.COLOR_LAB2RGB)\n    \n    # Save the preprocessed image\n    save_path = os.path.join(save_dir, os.path.basename(image_path))\n    cv2.imwrite(save_path, cv2.cvtColor(final_image, cv2.COLOR_RGB2BGR))\n    \n    return final_image / 255.0","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T08:32:27.480382Z","iopub.execute_input":"2025-09-26T08:32:27.480624Z","iopub.status.idle":"2025-09-26T08:32:27.48608Z","shell.execute_reply.started":"2025-09-26T08:32:27.480603Z","shell.execute_reply":"2025-09-26T08:32:27.485318Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"Preprocessing images and saving to disk...\")\nfor image_path in tqdm(df[\"id_code\"], desc=\"Processing Images\"):  # Add tqdm here\n    apply_clahe_and_save(image_path, save_dir)\nprint(\"Preprocessing complete!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T08:32:27.487563Z","iopub.execute_input":"2025-09-26T08:32:27.487804Z","iopub.status.idle":"2025-09-26T08:39:07.013088Z","shell.execute_reply.started":"2025-09-26T08:32:27.487783Z","shell.execute_reply":"2025-09-26T08:39:07.012071Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## LOADING PREPROCESSED DATA INTO TF DATASET","metadata":{}},{"cell_type":"code","source":"def load_preprocessed_image(image_path, label):\n    image = tf.io.read_file(image_path)\n    \n    image = tf.image.decode_png(image, channels=3)\n    image = tf.image.resize(image, [img_size, img_size])\n    image = tf.cast(image, tf.float32) / 255.0\n    \n    return image, label","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T08:39:07.014093Z","iopub.execute_input":"2025-09-26T08:39:07.014491Z","iopub.status.idle":"2025-09-26T08:39:07.018664Z","shell.execute_reply.started":"2025-09-26T08:39:07.014451Z","shell.execute_reply":"2025-09-26T08:39:07.017955Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"image_paths = [os.path.join(save_dir, os.path.basename(path)) for path in df[\"id_code\"]]\nlabels = df[\"diagnosis\"].values\ndataset = tf.data.Dataset.from_tensor_slices((image_paths, labels))\ndataset = dataset.shuffle(len(df)).map(load_preprocessed_image, num_parallel_calls=tf.data.AUTOTUNE)\ndataset = dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T08:39:07.019525Z","iopub.execute_input":"2025-09-26T08:39:07.019758Z","iopub.status.idle":"2025-09-26T08:39:07.282821Z","shell.execute_reply.started":"2025-09-26T08:39:07.019739Z","shell.execute_reply":"2025-09-26T08:39:07.282087Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## BEFORE AND AFTER CLACHE PREPROCESS","metadata":{}},{"cell_type":"code","source":"def visualize_clahe_effect(df_sample):\n    fig, axes = plt.subplots(len(df_sample), 2, figsize=(10, 5 * len(df_sample)))\n    \n    for i, row in enumerate(df_sample.itertuples()):\n        img_path = row.id_code\n        original = cv2.imread(img_path, cv2.IMREAD_COLOR)\n        original = cv2.resize(original, (img_size, img_size))\n        original = cv2.cvtColor(original, cv2.COLOR_BGR2RGB)\n        \n        processed_path = os.path.join(save_dir, os.path.basename(img_path))\n        processed = cv2.imread(processed_path, cv2.IMREAD_COLOR)\n        processed = cv2.cvtColor(processed, cv2.COLOR_BGR2RGB)\n        \n        axes[i, 0].imshow(original)\n        axes[i, 0].set_title(f\"Original - {row.diagnosis}\")\n        axes[i, 0].axis(\"off\")\n\n        axes[i, 1].imshow(processed)\n        axes[i, 1].set_title(f\"CLAHE Processed - {row.diagnosis}\")\n        axes[i, 1].axis(\"off\")\n    \n    plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T08:39:07.283692Z","iopub.execute_input":"2025-09-26T08:39:07.283986Z","iopub.status.idle":"2025-09-26T08:39:07.289906Z","shell.execute_reply.started":"2025-09-26T08:39:07.283955Z","shell.execute_reply":"2025-09-26T08:39:07.28923Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_sample = df.sample(5)\nvisualize_clahe_effect(df_sample)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T08:39:07.29076Z","iopub.execute_input":"2025-09-26T08:39:07.291009Z","iopub.status.idle":"2025-09-26T08:39:09.08789Z","shell.execute_reply.started":"2025-09-26T08:39:07.290989Z","shell.execute_reply":"2025-09-26T08:39:09.086485Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## SPLITTING AND PREFETCHING DATASET","metadata":{}},{"cell_type":"code","source":"def dataset_split(ds, train=0.7, val=0.15, test=0.15):\n    ds_size = len(ds)\n    train_size = int(ds_size * train)\n    val_size = int(ds_size * val)\n    \n    train_ds = ds.take(train_size)\n    val_ds = ds.skip(train_size).take(val_size)\n    test_ds = ds.skip(train_size + val_size)\n    \n    return train_ds, val_ds, test_ds","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T08:39:09.089078Z","iopub.execute_input":"2025-09-26T08:39:09.089442Z","iopub.status.idle":"2025-09-26T08:39:09.095605Z","shell.execute_reply.started":"2025-09-26T08:39:09.089402Z","shell.execute_reply":"2025-09-26T08:39:09.094604Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_ds, val_ds, test_ds = dataset_split(dataset)\ntrain_ds = train_ds.cache().shuffle(1000).prefetch(tf.data.AUTOTUNE)\nval_ds = val_ds.cache().prefetch(tf.data.AUTOTUNE)\ntest_ds = test_ds.cache().prefetch(tf.data.AUTOTUNE)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T08:39:09.096777Z","iopub.execute_input":"2025-09-26T08:39:09.09721Z","iopub.status.idle":"2025-09-26T08:39:09.139303Z","shell.execute_reply.started":"2025-09-26T08:39:09.097169Z","shell.execute_reply":"2025-09-26T08:39:09.138557Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## MULTIBRANCH CNN WITH TRANSFER LEARNING","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.applications import DenseNet201,ResNet50\nfrom sklearn.utils.class_weight import compute_class_weight","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T08:39:09.140135Z","iopub.execute_input":"2025-09-26T08:39:09.140389Z","iopub.status.idle":"2025-09-26T08:39:09.145931Z","shell.execute_reply.started":"2025-09-26T08:39:09.140366Z","shell.execute_reply":"2025-09-26T08:39:09.145294Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"base1 = DenseNet201(weights=\"imagenet\", include_top=False, input_shape=(img_size, img_size, 3))\nbase2 = ResNet50(weights=\"imagenet\", include_top=False, input_shape=(img_size, img_size, 3))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T08:39:09.146858Z","iopub.execute_input":"2025-09-26T08:39:09.14709Z","iopub.status.idle":"2025-09-26T08:39:17.099524Z","shell.execute_reply.started":"2025-09-26T08:39:09.14706Z","shell.execute_reply":"2025-09-26T08:39:17.098485Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"base1.trainable = True\nbase2.trainable = True","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T08:39:17.100532Z","iopub.execute_input":"2025-09-26T08:39:17.100786Z","iopub.status.idle":"2025-09-26T08:39:17.104668Z","shell.execute_reply.started":"2025-09-26T08:39:17.100764Z","shell.execute_reply":"2025-09-26T08:39:17.103692Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for layer in base1.layers[:-10]:  # Unfreeze the last 10 layers of EfficientNetB0\n    layer.trainable = False\nfor layer in base2.layers[:-10]:  # Unfreeze the last 10 layers of ResNet50\n    layer.trainable = False","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T08:39:17.105704Z","iopub.execute_input":"2025-09-26T08:39:17.105958Z","iopub.status.idle":"2025-09-26T08:39:17.132156Z","shell.execute_reply.started":"2025-09-26T08:39:17.105936Z","shell.execute_reply":"2025-09-26T08:39:17.131357Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"inputs = tf.keras.Input(shape=(img_size, img_size, 3))\nx1 = layers.GlobalAveragePooling2D()(base1(inputs))\nx2 = layers.GlobalAveragePooling2D()(base2(inputs))\nmerged = layers.Concatenate()([x1, x2])\nx = layers.Dense(256, activation=\"relu\")(merged)\nx = layers.Dropout(0.5)(x)\noutputs = layers.Dense(5, activation=\"softmax\")(x)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T08:39:17.133068Z","iopub.execute_input":"2025-09-26T08:39:17.133324Z","iopub.status.idle":"2025-09-26T08:39:17.178564Z","shell.execute_reply.started":"2025-09-26T08:39:17.133288Z","shell.execute_reply":"2025-09-26T08:39:17.177614Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"multibranch_model_1 = Model(inputs, outputs)\nmultibranch_model_1.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T08:39:17.179618Z","iopub.execute_input":"2025-09-26T08:39:17.179945Z","iopub.status.idle":"2025-09-26T08:39:17.246321Z","shell.execute_reply.started":"2025-09-26T08:39:17.179912Z","shell.execute_reply":"2025-09-26T08:39:17.245413Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"multibranch_model_1.compile(\n    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n    metrics=[\"accuracy\"]\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T08:39:17.249995Z","iopub.execute_input":"2025-09-26T08:39:17.250241Z","iopub.status.idle":"2025-09-26T08:39:17.516083Z","shell.execute_reply.started":"2025-09-26T08:39:17.250219Z","shell.execute_reply":"2025-09-26T08:39:17.515324Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class_weights = compute_class_weight(\"balanced\", classes=np.unique(labels), y=labels)\nclass_weights = dict(enumerate(class_weights))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T08:39:17.517662Z","iopub.execute_input":"2025-09-26T08:39:17.517895Z","iopub.status.idle":"2025-09-26T08:39:17.523644Z","shell.execute_reply.started":"2025-09-26T08:39:17.517875Z","shell.execute_reply":"2025-09-26T08:39:17.52282Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def lr_scheduler(epoch, lr):\n    if epoch > 0 and epoch % 10 == 0:  # Reduce LR every 10 epochs\n        return lr * 0.1\n    return lr\n\nlr_callback = tf.keras.callbacks.LearningRateScheduler(lr_scheduler)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T08:39:17.524709Z","iopub.execute_input":"2025-09-26T08:39:17.525053Z","iopub.status.idle":"2025-09-26T08:39:17.537662Z","shell.execute_reply.started":"2025-09-26T08:39:17.525019Z","shell.execute_reply":"2025-09-26T08:39:17.536855Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"early_stopping = tf.keras.callbacks.EarlyStopping(\n    monitor=\"val_loss\",\n    patience=5,  # Stop after 5 epochs without improvement\n    restore_best_weights=True\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T08:39:17.538506Z","iopub.execute_input":"2025-09-26T08:39:17.538834Z","iopub.status.idle":"2025-09-26T08:39:17.556801Z","shell.execute_reply.started":"2025-09-26T08:39:17.538803Z","shell.execute_reply":"2025-09-26T08:39:17.555886Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"multibranch_history = multibranch_model_1.fit(\n    train_ds,\n    epochs=50,\n    batch_size=batch_size,\n    verbose=1,\n    class_weight=class_weights,\n    validation_data=val_ds,\n    callbacks=[lr_callback,early_stopping]\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T08:39:17.557602Z","iopub.execute_input":"2025-09-26T08:39:17.557973Z","iopub.status.idle":"2025-09-26T08:49:02.90023Z","shell.execute_reply.started":"2025-09-26T08:39:17.557947Z","shell.execute_reply":"2025-09-26T08:49:02.899494Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"multibranch_model_1.save(\"multibranch_model_1.keras\")\nmultibranch_model_1.save(\"multibranch_model_1.h5\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T08:49:02.901224Z","iopub.execute_input":"2025-09-26T08:49:02.901561Z","iopub.status.idle":"2025-09-26T08:49:07.046078Z","shell.execute_reply.started":"2025-09-26T08:49:02.901536Z","shell.execute_reply":"2025-09-26T08:49:07.045092Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_loss, test_acc = multibranch_model_1.evaluate(test_ds)\nprint(f\"Test Accuracy: {test_acc * 100:.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T08:49:07.046959Z","iopub.execute_input":"2025-09-26T08:49:07.047243Z","iopub.status.idle":"2025-09-26T08:49:29.258433Z","shell.execute_reply.started":"2025-09-26T08:49:07.047219Z","shell.execute_reply":"2025-09-26T08:49:29.257652Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 2D CNN","metadata":{}},{"cell_type":"code","source":"def build_2d_cnn(input_shape=(224, 224, 3), num_classes=5):\n    inputs = tf.keras.Input(shape=input_shape)\n    \n    # Convolutional layers\n    x = layers.Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\")(inputs)\n    x = layers.MaxPooling2D((2, 2))(x)\n    x = layers.Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\")(x)\n    x = layers.MaxPooling2D((2, 2))(x)\n    x = layers.Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\")(x)\n    x = layers.MaxPooling2D((2, 2))(x)\n    \n    # Fully connected layers\n    x = layers.Flatten()(x)\n    x = layers.Dense(256, activation=\"relu\")(x)\n    x = layers.Dropout(0.5)(x)\n    \n    # Output layer\n    outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n    \n    # Build the model\n    cnn_model = Model(inputs, outputs)\n    return cnn_model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T08:49:29.259193Z","iopub.execute_input":"2025-09-26T08:49:29.259465Z","iopub.status.idle":"2025-09-26T08:49:29.265319Z","shell.execute_reply.started":"2025-09-26T08:49:29.259436Z","shell.execute_reply":"2025-09-26T08:49:29.264508Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"cnn_model = build_2d_cnn(input_shape=(img_size, img_size, 3), num_classes=5)\ncnn_model.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T08:49:29.26613Z","iopub.execute_input":"2025-09-26T08:49:29.266437Z","iopub.status.idle":"2025-09-26T08:49:29.345315Z","shell.execute_reply.started":"2025-09-26T08:49:29.266406Z","shell.execute_reply":"2025-09-26T08:49:29.344445Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"cnn_model.compile(\n    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n    metrics=[\"accuracy\"]\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T08:49:29.346189Z","iopub.execute_input":"2025-09-26T08:49:29.346497Z","iopub.status.idle":"2025-09-26T08:49:29.354602Z","shell.execute_reply.started":"2025-09-26T08:49:29.346473Z","shell.execute_reply":"2025-09-26T08:49:29.353744Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"cnn_history = cnn_model.fit(\n    train_ds,\n    epochs=40,\n    batch_size=batch_size,\n    verbose=1,\n    class_weight=class_weights,\n    validation_data=val_ds,\n    callbacks=[lr_callback]\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T08:49:29.355395Z","iopub.execute_input":"2025-09-26T08:49:29.355637Z","iopub.status.idle":"2025-09-26T08:51:07.566976Z","shell.execute_reply.started":"2025-09-26T08:49:29.355615Z","shell.execute_reply":"2025-09-26T08:51:07.565999Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"cnn_model.save(\"cnn_model_1.keras\")\ncnn_model.save(\"cnn_model_1.h5\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T08:51:07.568216Z","iopub.execute_input":"2025-09-26T08:51:07.56857Z","iopub.status.idle":"2025-09-26T08:51:09.691072Z","shell.execute_reply.started":"2025-09-26T08:51:07.568535Z","shell.execute_reply":"2025-09-26T08:51:09.690389Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_loss, test_acc = cnn_model.evaluate(test_ds)\nprint(f\"Test Accuracy: {test_acc * 100:.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T08:51:09.692055Z","iopub.execute_input":"2025-09-26T08:51:09.692402Z","iopub.status.idle":"2025-09-26T08:51:10.769832Z","shell.execute_reply.started":"2025-09-26T08:51:09.69237Z","shell.execute_reply":"2025-09-26T08:51:10.769096Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## VISUALIZATION OF MODEL TRAININGS","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# ✅ Convert only if still a History object\nif hasattr(multibranch_history, 'history'):\n    multibranch_history = multibranch_history.history\n\nif hasattr(cnn_history, 'history'):\n    cnn_history = cnn_history.history\n\n# ✅ Plot Accuracy and Loss Comparison\nfig, axes = plt.subplots(1, 2, figsize=(16, 6))\n\n# --- Accuracy ---\naxes[0].plot(multibranch_history['accuracy'], label='Multi-Branch CNN Training Accuracy')\naxes[0].plot(multibranch_history['val_accuracy'], label='Multi-Branch CNN Validation Accuracy')\naxes[0].plot(cnn_history['accuracy'], label='2D CNN Training Accuracy')\naxes[0].plot(cnn_history['val_accuracy'], label='2D CNN Validation Accuracy')\naxes[0].set_title('Accuracy Comparison')\naxes[0].set_xlabel('Epoch')\naxes[0].set_ylabel('Accuracy')\naxes[0].legend()\naxes[0].grid(True)\n\n# --- Loss ---\naxes[1].plot(multibranch_history['loss'], label='Multi-Branch CNN Training Loss')\naxes[1].plot(multibranch_history['val_loss'], label='Multi-Branch CNN Validation Loss')\naxes[1].plot(cnn_history['loss'], label='2D CNN Training Loss')\naxes[1].plot(cnn_history['val_loss'], label='2D CNN Validation Loss')\naxes[1].set_title('Loss Comparison')\naxes[1].set_xlabel('Epoch')\naxes[1].set_ylabel('Loss')\naxes[1].legend()\naxes[1].grid(True)\n\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T08:54:36.326063Z","iopub.execute_input":"2025-09-26T08:54:36.32642Z","iopub.status.idle":"2025-09-26T08:54:36.805824Z","shell.execute_reply.started":"2025-09-26T08:54:36.326385Z","shell.execute_reply":"2025-09-26T08:54:36.804925Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"multibranch_predictions = multibranch_model_1.predict(test_ds)\ncnn_predictions = cnn_model.predict(test_ds)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T08:54:42.033767Z","iopub.execute_input":"2025-09-26T08:54:42.034089Z","iopub.status.idle":"2025-09-26T08:55:19.185488Z","shell.execute_reply.started":"2025-09-26T08:54:42.034064Z","shell.execute_reply":"2025-09-26T08:55:19.18473Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"multibranch_class_labels = np.argmax(multibranch_predictions, axis=1) \ncnn_class_labels = np.argmax(cnn_predictions, axis=1)\n\ntrue_labels = np.concatenate([y for x, y in test_ds], axis=0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T08:59:27.897744Z","iopub.execute_input":"2025-09-26T08:59:27.898042Z","iopub.status.idle":"2025-09-26T08:59:27.910476Z","shell.execute_reply.started":"2025-09-26T08:59:27.898018Z","shell.execute_reply":"2025-09-26T08:59:27.909585Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"multibranch_cm = confusion_matrix(true_labels, multibranch_class_labels)\ncnn_cm = confusion_matrix(true_labels, cnn_class_labels)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T08:59:30.677999Z","iopub.execute_input":"2025-09-26T08:59:30.678369Z","iopub.status.idle":"2025-09-26T08:59:30.685676Z","shell.execute_reply.started":"2025-09-26T08:59:30.678334Z","shell.execute_reply":"2025-09-26T08:59:30.684744Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(16, 6))\n\nplt.subplot(1, 2, 1)\nsns.heatmap(multibranch_cm, annot=True, fmt='d', cmap='Blues', cbar=False)\nplt.title('Multi-Branch CNN Confusion Matrix')\nplt.xlabel('Predicted Labels')\nplt.ylabel('True Labels')\n\nplt.subplot(1, 2, 2)\nsns.heatmap(cnn_cm, annot=True, fmt='d', cmap='Greens', cbar=False)\nplt.title('2D CNN Confusion Matrix')\nplt.xlabel('Predicted Labels')\nplt.ylabel('True Labels')\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T08:59:33.99257Z","iopub.execute_input":"2025-09-26T08:59:33.992899Z","iopub.status.idle":"2025-09-26T08:59:35.001475Z","shell.execute_reply.started":"2025-09-26T08:59:33.992868Z","shell.execute_reply":"2025-09-26T08:59:35.000548Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## ENSEMBLE MODEL","metadata":{}},{"cell_type":"code","source":"multibranch_model=tf.keras.models.load_model(\"/kaggle/working/multibranch_model_1.h5\")\ncnn_model = tf.keras.models.load_model(\"/kaggle/working/cnn_model_1.h5\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T08:59:41.270202Z","iopub.execute_input":"2025-09-26T08:59:41.270532Z","iopub.status.idle":"2025-09-26T08:59:45.429991Z","shell.execute_reply.started":"2025-09-26T08:59:41.270498Z","shell.execute_reply":"2025-09-26T08:59:45.429195Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"weight_multibranch = 0.7\nweight_cnn = 0.3","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T08:59:49.682229Z","iopub.execute_input":"2025-09-26T08:59:49.682632Z","iopub.status.idle":"2025-09-26T08:59:49.686308Z","shell.execute_reply.started":"2025-09-26T08:59:49.682603Z","shell.execute_reply":"2025-09-26T08:59:49.685521Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"ensemble_predictions = (weight_multibranch * multibranch_predictions) + (weight_cnn * cnn_predictions)\nensemble_class_labels = np.argmax(ensemble_predictions, axis=1)\ntrue_labels = np.concatenate([y for x, y in test_ds], axis=0)\nensemble_accuracy = np.mean(ensemble_class_labels == true_labels)\nprint(f\"Ensemble Accuracy: {ensemble_accuracy * 100:.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T08:59:53.405635Z","iopub.execute_input":"2025-09-26T08:59:53.405934Z","iopub.status.idle":"2025-09-26T08:59:53.41982Z","shell.execute_reply.started":"2025-09-26T08:59:53.405909Z","shell.execute_reply":"2025-09-26T08:59:53.41904Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(12, 6))\n\nplt.subplot(1, 3, 1)\nplt.hist(multibranch_class_labels, bins=5, range=(0, 5), alpha=0.7, color='blue')\nplt.title('Multi-Branch CNN Predictions')\nplt.xlabel('Class')\nplt.ylabel('Frequency')\n\nplt.subplot(1, 3, 2)\nplt.hist(cnn_class_labels, bins=5, range=(0, 5), alpha=0.7, color='green')\nplt.title('2D CNN Predictions')\nplt.xlabel('Class')\nplt.ylabel('Frequency')\n\n# Ensemble predictions\nplt.subplot(1, 3, 3)\nplt.hist(ensemble_class_labels, bins=5, range=(0, 5), alpha=0.7, color='red')\nplt.title('Ensemble Predictions')\nplt.xlabel('Class')\nplt.ylabel('Frequency')\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T08:59:58.747992Z","iopub.execute_input":"2025-09-26T08:59:58.74833Z","iopub.status.idle":"2025-09-26T08:59:59.246667Z","shell.execute_reply.started":"2025-09-26T08:59:58.748291Z","shell.execute_reply":"2025-09-26T08:59:59.245827Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## PREDICTING WITH USER INPUTS","metadata":{}},{"cell_type":"code","source":"import cv2\nimport numpy as np\nimport tensorflow as tf\nimport matplotlib.pyplot as plt","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T09:00:09.035135Z","iopub.execute_input":"2025-09-26T09:00:09.03545Z","iopub.status.idle":"2025-09-26T09:00:09.039391Z","shell.execute_reply.started":"2025-09-26T09:00:09.035424Z","shell.execute_reply":"2025-09-26T09:00:09.038426Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def preprocess_image(image_path, img_size=224):\n    \"\"\"\n    Preprocesses the image using CLAHE and resizes it.\n    \"\"\"\n    image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n    if image is None:\n        raise ValueError(f\"Unable to read image at path: {image_path}\")\n\n    image = cv2.resize(image, (img_size, img_size))\n    lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n    l, a, b = cv2.split(lab)\n    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n    l_clahe = clahe.apply(l)\n\n    merged_lab = cv2.merge((l_clahe, a, b))\n    final_image = cv2.cvtColor(merged_lab, cv2.COLOR_LAB2RGB)\n\n    final_image = final_image / 255.0  # Normalize to [0, 1]\n    return final_image","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T09:00:16.338842Z","iopub.execute_input":"2025-09-26T09:00:16.339143Z","iopub.status.idle":"2025-09-26T09:00:16.34474Z","shell.execute_reply.started":"2025-09-26T09:00:16.339119Z","shell.execute_reply":"2025-09-26T09:00:16.343751Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def saliency_map(model, img_array):\n    \"\"\"\n    Generates a Saliency Map for a given model and image.\n    \"\"\"\n    img_tensor = tf.convert_to_tensor(img_array)\n    with tf.GradientTape() as tape:\n        tape.watch(img_tensor)\n        predictions = model(img_tensor)\n        top_pred = tf.argmax(predictions[0])\n        loss = predictions[:, top_pred]\n\n    grads = tape.gradient(loss, img_tensor)[0]\n    saliency = tf.reduce_max(tf.abs(grads), axis=-1).numpy()\n    return saliency","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T09:00:19.95412Z","iopub.execute_input":"2025-09-26T09:00:19.954467Z","iopub.status.idle":"2025-09-26T09:00:19.959438Z","shell.execute_reply.started":"2025-09-26T09:00:19.954438Z","shell.execute_reply":"2025-09-26T09:00:19.958605Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def predict_with_explanations(image_path, multibranch_model, cnn_model, img_size=224, weight_multibranch=0.7, weight_cnn=0.3):\n    \"\"\"\n    Predicts the class probabilities for an image using multi-branch CNN, 2D CNN, and ensemble.\n    Also generates Saliency Map explanations for each model.\n\n    Args:\n        image_path (str): Path to the input image.\n        multibranch_model (tf.keras.Model): Trained multi-branch CNN model.\n        cnn_model (tf.keras.Model): Trained 2D CNN model.\n        img_size (int): Size of the input image (default: 224).\n        weight_multibranch (float): Weight for multi-branch CNN in the ensemble (default: 0.7).\n        weight_cnn (float): Weight for 2D CNN in the ensemble (default: 0.3).\n\n    Returns:\n        dict: A dictionary containing the predictions, confidence percentages, and Saliency Maps.\n    \"\"\"\n    # Preprocess the image\n    preprocessed_image = preprocess_image(image_path, img_size)\n    img_array = np.expand_dims(preprocessed_image, axis=0)  # Add batch dimension\n\n    # Get predictions from multi-branch CNN\n    multibranch_probs = multibranch_model.predict(img_array, verbose=0)[0]\n    multibranch_class = np.argmax(multibranch_probs)\n    multibranch_confidence = float(multibranch_probs[multibranch_class])\n\n    # Get predictions from 2D CNN\n    cnn_probs = cnn_model.predict(img_array, verbose=0)[0]\n    cnn_class = np.argmax(cnn_probs)\n    cnn_confidence = float(cnn_probs[cnn_class])\n\n    # Combine predictions using weighted average for ensemble\n    ensemble_probs = (weight_multibranch * multibranch_probs) + (weight_cnn * cnn_probs)\n    ensemble_class = np.argmax(ensemble_probs)\n    ensemble_confidence = float(ensemble_probs[ensemble_class])\n\n    # Generate Saliency Map for multi-branch CNN\n    multibranch_saliency = saliency_map(multibranch_model, img_array)\n\n    # Generate Saliency Map for 2D CNN\n    cnn_saliency = saliency_map(cnn_model, img_array)\n\n    # Return results as a dictionary\n    results = {\n        \"multi_branch_cnn\": {\n            \"class\": int(multibranch_class),\n            \"confidence\": multibranch_confidence,\n            \"probabilities\": [float(prob) for prob in multibranch_probs],\n            \"saliency_map\": multibranch_saliency,\n        },\n        \"2d_cnn\": {\n            \"class\": int(cnn_class),\n            \"confidence\": cnn_confidence,\n            \"probabilities\": [float(prob) for prob in cnn_probs],\n            \"saliency_map\": cnn_saliency,\n        },\n        \"ensemble\": {\n            \"class\": int(ensemble_class),\n            \"confidence\": ensemble_confidence,\n            \"probabilities\": [float(prob) for prob in ensemble_probs],\n        },\n    }\n    return results","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T09:00:23.101403Z","iopub.execute_input":"2025-09-26T09:00:23.101704Z","iopub.status.idle":"2025-09-26T09:00:23.109014Z","shell.execute_reply.started":"2025-09-26T09:00:23.10168Z","shell.execute_reply":"2025-09-26T09:00:23.108025Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def visualize_results(results, original_image):\n    \"\"\"\n    Visualizes the predictions and Saliency Map explanations.\n\n    Args:\n        results (dict): Dictionary containing predictions and Saliency Maps.\n        original_image (np.array): Original input image.\n    \"\"\"\n    plt.figure(figsize=(18, 12))\n\n    # Display original image\n    plt.subplot(2, 2, 1)\n    plt.imshow(original_image)\n    plt.title(\"Original Image\")\n    plt.axis(\"off\")\n\n    # Display Saliency Map for multi-branch CNN\n    plt.subplot(2, 2, 2)\n    plt.imshow(results[\"multi_branch_cnn\"][\"saliency_map\"], cmap=\"hot\")\n    plt.title(\"Saliency Map (Multi-Branch CNN)\")\n    plt.axis(\"off\")\n\n    # Display Saliency Map for 2D CNN\n    plt.subplot(2, 2, 4)\n    plt.imshow(results[\"2d_cnn\"][\"saliency_map\"], cmap=\"hot\")\n    plt.title(\"Saliency Map (2D CNN)\")\n    plt.axis(\"off\")\n\n    plt.tight_layout()\n    plt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T09:00:27.802773Z","iopub.execute_input":"2025-09-26T09:00:27.80307Z","iopub.status.idle":"2025-09-26T09:00:27.80884Z","shell.execute_reply.started":"2025-09-26T09:00:27.803046Z","shell.execute_reply":"2025-09-26T09:00:27.807643Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Example usage\nimage_path = \"/kaggle/input/aptos2019-blindness-detection/test_images/006efc72b638.png\"\nresults = predict_with_explanations(image_path, multibranch_model_1, cnn_model)\n\n# Print predictions\nprint(\"Multi-Branch CNN Predictions:\")\nprint(f\"Class: {results['multi_branch_cnn']['class']}\")\nprint(f\"Confidence: {results['multi_branch_cnn']['confidence'] * 100:.2f}%\")\nprint(f\"Probabilities: {results['multi_branch_cnn']['probabilities']}\")\n\nprint(\"\\n2D CNN Predictions:\")\nprint(f\"Class: {results['2d_cnn']['class']}\")\nprint(f\"Confidence: {results['2d_cnn']['confidence'] * 100:.2f}%\")\nprint(f\"Probabilities: {results['2d_cnn']['probabilities']}\")\n\nprint(\"\\nEnsemble Predictions:\")\nprint(f\"Class: {results['ensemble']['class']}\")\nprint(f\"Confidence: {results['ensemble']['confidence'] * 100:.2f}%\")\nprint(f\"Probabilities: {results['ensemble']['probabilities']}\")\n\n# Visualize results\noriginal_image = cv2.cvtColor(cv2.imread(image_path), cv2.COLOR_BGR2RGB)\nvisualize_results(results, original_image)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T09:00:32.672254Z","iopub.execute_input":"2025-09-26T09:00:32.67262Z","iopub.status.idle":"2025-09-26T09:00:59.075671Z","shell.execute_reply.started":"2025-09-26T09:00:32.672592Z","shell.execute_reply":"2025-09-26T09:00:59.074593Z"}},"outputs":[],"execution_count":null}]}