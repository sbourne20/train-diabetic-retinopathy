#!/bin/bash

# Activate virtual environment
source venv/bin/activate

# Set PyTorch memory management
export PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True

# 5-CLASS DR + MobileNetV2 Paper Replication Training Script
echo "üè• 5-CLASS DR + MobileNetV2 Paper Replication (v1)"
echo "===================================================================="
echo "üéØ Target: 92%+ accuracy (Paper's result: 92.00% on APTOS 2019)"
echo "üìä Dataset: 5-Class Perfectly Balanced (53,935 images)"
echo "üèóÔ∏è Model: MobileNetV2 (3.5M params - lightweight)"
echo "üîó System: V100 16GB GPU optimized"
echo ""

# Create output directory for 5-class MobileNet results
mkdir -p ./mobilenet_5class_results

echo "üî¨ 5-CLASS MobileNetV2 OVO ENSEMBLE Configuration (Paper Replication v1):"
echo "  - Dataset: ./dataset_eyepacs_5class_balanced"
echo "  - Classes: 5 (0: No DR, 1: Mild NPDR, 2: Moderate NPDR, 3: Severe NPDR, 4: PDR)"
echo "  - Total images: 53,935 (Train: 37,750 | Val: 8,090 | Test: 8,095)"
echo "  - Perfect balance: 10,787 per class (1.00:1 ratio)"
echo ""
echo "üìä WHY MOBILENETV2 (PAPER'S BEST)?"
echo "  ‚úÖ Paper's result: 92.00% accuracy (best performer vs DenseNet 90.18%)"
echo "  ‚úÖ Lightweight: 3.5M parameters (vs EfficientNetB2 9.2M)"
echo "  ‚úÖ Fast inference: Optimized for mobile/edge deployment"
echo "  ‚úÖ Proven medical imaging: Widely used in DR detection"
echo "  ‚úÖ Better than your previous: EfficientNetB2 64.20%, DenseNet121 64.84%"
echo ""
echo "üéØ v1 STRATEGY - PAPER'S PROVEN CONFIGURATION:"
echo "  - Image size: 224√ó224 (Paper's standard, NOT 260 or 299)"
echo "  - Batch size: 32 (Paper's setting, NOT 8 or 10)"
echo "  - Learning rate: 1e-3 (Paper's setting, NOT 8e-5 or 9e-5)"
echo "  - Weight decay: 1e-4 (Paper's standard regularization)"
echo "  - Dropout: 0.5 (Paper's conservative setting, NOT 0.28 or 0.32)"
echo "  - Label smoothing: 0.0 (DISABLED - paper didn't use it)"
echo "  - CLAHE: DISABLED (paper used simple preprocessing)"
echo "  - SMOTE: N/A (dataset already balanced)"
echo "  - Focal loss: DISABLED (paper used simple Cross-Entropy)"
echo "  - Augmentation: SIMPLE (rotation 45¬∞, flip, zoom 0.2)"
echo "  - Scheduler: Cosine with 5-epoch warmup (NOT 10)"
echo "  - Patience: 15 epochs (shorter for faster training)"
echo "  - Epochs: 50 (Paper's setting, NOT 100)"
echo ""
echo "‚ö†Ô∏è  CRITICAL DIFFERENCES FROM YOUR PREVIOUS TRAINING:"
echo "  HYPERPARAMETER          | Previous (Failed)  | Paper (Success)    | Change"
echo "  ------------------------|--------------------|--------------------|-------------"
echo "  Architecture            | EfficientNetB2     | MobileNetV2        | Simpler"
echo "  Image Size              | 260√ó260            | 224√ó224            | -14% pixels"
echo "  Batch Size              | 8                  | 32                 | +300%"
echo "  Learning Rate           | 8e-5               | 1e-3               | +1,150%"
echo "  Dropout                 | 0.28               | 0.5                | +79%"
echo "  Label Smoothing         | 0.10               | 0.0                | REMOVED"
echo "  CLAHE                   | ENABLED            | DISABLED           | REMOVED"
echo "  Focal Loss              | ENABLED            | DISABLED           | REMOVED"
echo "  Warmup Epochs           | 10                 | 5                  | -50%"
echo "  Total Epochs            | 100                | 50                 | -50%"
echo ""
echo "üìà EXPECTED RESULTS (Based on Paper's APTOS 2019):"
echo "  Individual Binary Pairs:"
echo "    ‚Ä¢ Strong pairs (0v3, 0v4): 97-99%"
echo "    ‚Ä¢ Good pairs (0v1, 0v2, 1v3, 1v4, 2v4): 85-95%"
echo "    ‚Ä¢ Weak pairs (1v2, 2v3, 3v4): 77-83%"
echo "    ‚Ä¢ Average pair accuracy: ~92%"
echo "  "
echo "  Final Ensemble Performance:"
echo "    ‚Ä¢ Target accuracy: 92%+"
echo "    ‚Ä¢ Medical grade threshold: ‚â•90%"
echo "    ‚Ä¢ Research quality: ‚â•85%"
echo ""

# Train 5-Class with MobileNetV2 (Paper Replication)
python3 ensemble_5class_trainer.py \
    --mode train \
    --dataset_path ./dataset_eyepacs_5class_balanced \
    --output_dir ./mobilenet_5class_results \
    --experiment_name "5class_mobilenet_v2_paper_replication" \
    --base_models mobilenet_v2 \
    --num_classes 5 \
    --img_size 224 \
    --batch_size 32 \
    --epochs 50 \
    --learning_rate 1e-3 \
    --weight_decay 1e-4 \
    --ovo_dropout 0.5 \
    --freeze_weights false \
    --enable_medical_augmentation \
    --rotation_range 45.0 \
    --brightness_range 0.2 \
    --contrast_range 0.2 \
    --label_smoothing 0.0 \
    --scheduler cosine \
    --warmup_epochs 5 \
    --validation_frequency 1 \
    --checkpoint_frequency 5 \
    --patience 15 \
    --early_stopping_patience 10 \
    --target_accuracy 0.92 \
    --max_grad_norm 1.0 \
    --seed 42 \
    --device cuda \
    --no_wandb

echo ""
echo "‚úÖ 5-CLASS MobileNetV2 OVO ENSEMBLE training completed!"
echo ""
echo "üìä MOBILENETV2 vs YOUR PREVIOUS MODELS COMPARISON:"
echo ""
echo "  Parameter          | DenseNet121 (v3) | EfficientNetB2 (v1) | MobileNetV2 (v1) | Source"
echo "  -------------------|------------------|---------------------|------------------|------------------"
echo "  Result             | 64.84%           | 64.20%              | TARGET: 92%      | Paper vs Yours"
echo "  Architecture       | Dense Blocks     | Compound Scaling    | Inverted Residual| Design"
echo "  Parameters         | 8.0M             | 9.2M                | 3.5M             | Efficiency"
echo "  Image Size         | 299√ó299          | 260√ó260             | 224√ó224          | Input"
echo "  Batch Size         | 10               | 8                   | 32               | Training"
echo "  Learning Rate      | 9e-5             | 8e-5                | 1e-3             | Optimization"
echo "  Dropout            | 0.32             | 0.28                | 0.5              | Regularization"
echo "  Label Smoothing    | 0.11             | 0.10                | 0.0              | Loss"
echo "  CLAHE              | ENABLED          | ENABLED             | DISABLED         | Preprocessing"
echo "  Focal Loss         | ENABLED          | ENABLED             | DISABLED         | Loss Function"
echo ""
echo "üéØ EXPECTED RESULTS ANALYSIS:"
echo ""
echo "  IF ACCURACY ‚â• 90%:"
echo "    ‚úÖ SUCCESS! Paper configuration works on your dataset"
echo "    ‚úÖ Proceed to train ResNet50 and DenseNet121 with same settings"
echo "    ‚úÖ Then create meta-ensemble (3 models) ‚Üí Expected: 93-95%"
echo ""
echo "  IF ACCURACY 85-90%:"
echo "    ‚ö†Ô∏è  GOOD! Close to paper's result"
echo "    ‚ö†Ô∏è  Dataset quality may differ from APTOS 2019"
echo "    ‚ö†Ô∏è  Still suitable for meta-ensemble"
echo "    üí° Try: Increase epochs to 80, or adjust learning rate to 8e-4"
echo ""
echo "  IF ACCURACY 75-85%:"
echo "    ‚ö†Ô∏è  MODERATE improvement over previous (64%)"
echo "    ‚ö†Ô∏è  Hyperparameters working but dataset issues possible"
echo "    üí° Try: Review image quality, increase batch size to 64"
echo ""
echo "  IF ACCURACY < 75%:"
echo "    ‚ùå UNEXPECTED - Debug required"
echo "    üí° Check: Dataset balance, training logs, GPU utilization"
echo "    üí° Try: Longer training (100 epochs), add back focal loss"
echo ""
echo "üìà KEY PERFORMANCE INDICATORS TO MONITOR:"
echo "  1. Binary Pair Accuracies (should be 77-99%)"
echo "  2. Weak Pairs (1v2, 3v4) - Critical for ensemble"
echo "  3. Training vs Validation Gap (overfitting indicator)"
echo "  4. Loss curves (should converge smoothly)"
echo "  5. Confusion matrix (class-wise performance)"
echo ""
echo "‚ö†Ô∏è  MONITORING CHECKPOINTS (Check These During Training):"
echo "  Epoch 5:  Expect ~70-75% (warmup complete)"
echo "  Epoch 10: Expect ~80-85% (learning progressing)"
echo "  Epoch 20: Expect ~88-90% (approaching target)"
echo "  Epoch 30: Expect ~90-92% (should reach target)"
echo "  Epoch 50: Expect ~92%+ (final performance)"
echo ""
echo "üîß NEXT STEPS AFTER TRAINING:"
echo "  1. Analyze results:"
echo "     python3 model_analyzer.py --model ./mobilenet_5class_results/models/ovo_ensemble_best.pth"
echo ""
echo "  2. Compare with paper:"
echo "     - Paper's MobileNet: 92.00%"
echo "     - Your result: Check analyzer output"
echo "     - Gap analysis: Why different (if any)?"
echo ""
echo "  3. If successful (‚â•88%):"
echo "     - Train ResNet50 with same configuration"
echo "     - Train DenseNet121 with same configuration"
echo "     - Create meta-ensemble of all 3"
echo ""
echo "  4. If unsuccessful (<85%):"
echo "     - Review training logs for issues"
echo "     - Check dataset quality"
echo "     - Try alternative configurations"
echo ""
echo "üöÄ Training started at: $(date)"
echo "üìÅ Results directory: ./mobilenet_5class_results/"
echo "üìä Monitor progress: tail -f ./mobilenet_5class_results/logs/*.log"
echo ""
echo "üí° REMINDER: This configuration exactly replicates the paper that achieved 92%"
echo "    Any significant deviation (<85%) suggests dataset or environment differences"
echo ""
