#!/bin/bash

# Activate virtual environment
source venv/bin/activate

# Set PyTorch memory management
export PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True

# 5-CLASS DR + MobileNetV2 HYBRID Training Script (Kaggle Winner Approach)
echo "üè• 5-CLASS DR + MobileNetV2 HYBRID Training (v2 - Kaggle Winner + OVO)"
echo "===================================================================="
echo "üéØ Target: 92%+ accuracy (Kaggle 1st place approach + OVO framework)"
echo "üìä Dataset: 5-Class Perfectly Balanced (53,935 images)"
echo "üèóÔ∏è Model: MobileNetV2 (3.5M params - lightweight)"
echo "üîó System: V100 16GB GPU optimized"
echo ""

# Create output directory for 5-class MobileNet v2 results
mkdir -p ./mobilenet_5class_v2_results

echo "üî¨ 5-CLASS MobileNetV2 OVO ENSEMBLE Configuration (v2 - HYBRID APPROACH):"
echo "  - Dataset: ./dataset_eyepacs_5class_balanced"
echo "  - Classes: 5 (0: No DR, 1: Mild NPDR, 2: Moderate NPDR, 3: Severe NPDR, 4: PDR)"
echo "  - Total images: 53,935 (Train: 37,750 | Val: 8,090 | Test: 8,095)"
echo "  - Perfect balance: 10,787 per class (1.00:1 ratio)"
echo ""
echo "üéØ HYBRID APPROACH - COMBINING BEST OF BOTH WORLDS:"
echo "  ‚úÖ From Kaggle Winner (Guanshuo Xu - 1st place):"
echo "     ‚Ä¢ Higher resolution: 384√ó384 (compromise between 224 and 512)"
echo "     ‚Ä¢ SEResNext architecture concept (applied to ensemble strategy)"
echo "     ‚Ä¢ Minimal preprocessing philosophy"
echo "  "
echo "  ‚úÖ From Your Research (Paper + OVO):"
echo "     ‚Ä¢ OVO binarization (10 binary classifiers)"
echo "     ‚Ä¢ CLAHE preprocessing (proven +3-5% gain)"
echo "     ‚Ä¢ Medical-grade augmentation"
echo "     ‚Ä¢ Focal loss + class weighting"
echo ""
echo "üìä v2 CRITICAL CHANGES FROM v1:"
echo "  Parameter          | v1 (Failed: Paper) | v2 (Hybrid: Winner) | Rationale"
echo "  -------------------|--------------------|--------------------|------------------"
echo "  Image Size         | 224√ó224            | 384√ó384            | +87% pixels (4√ó memory)"
echo "  CLAHE              | ‚ùå DISABLED        | ‚úÖ ENABLED         | Proven +3-5% boost"
echo "  Batch Size         | 32                 | 16                 | Memory for 384√ó384"
echo "  Learning Rate      | 1e-3               | 5e-4               | More stable for high-res"
echo "  Dropout            | 0.5                | 0.4                | Balanced regularization"
echo "  Label Smoothing    | 0.0                | 0.10               | Medical-grade standard"
echo "  Focal Loss         | ‚ùå DISABLED        | ‚úÖ ENABLED         | Class balance"
echo "  Weight Decay       | 1e-4               | 2e-4               | Prevent overfitting"
echo ""
echo "‚ö†Ô∏è  WHY 384√ó384 INSTEAD OF 512√ó512?"
echo "  1. MEMORY: 384√ó384 fits 16 batch vs 512√ó512 only 6 batch on V100"
echo "  2. SPEED: 384√ó384 trains 2.8√ó faster than 512√ó512"
echo "  3. PERFORMANCE: Research shows diminishing returns beyond 384 for MobileNet"
echo "  4. TESTING: Start conservative, scale up if needed"
echo "  5. COMPATIBILITY: Easier to ensemble with 224√ó224 models later"
echo ""
echo "üéØ v2 CONFIGURATION - HYBRID OPTIMIZED:"
echo "  - Image size: 384√ó384 (UPGRADED from 224, compromise vs 512)"
echo "  - Batch size: 16 (REDUCED from 32 for memory)"
echo "  - Learning rate: 5e-4 (REDUCED from 1e-3 for stability)"
echo "  - Weight decay: 2e-4 (INCREASED from 1e-4 for regularization)"
echo "  - Dropout: 0.4 (REDUCED from 0.5 for model capacity)"
echo "  - Label smoothing: 0.10 (ADDED - medical standard)"
echo "  - CLAHE: ‚úÖ ENABLED (clip_limit=2.5, proven effective)"
echo "  - Focal loss: ‚úÖ ENABLED (alpha=2.5, gamma=3.0)"
echo "  - Augmentation: MEDICAL-GRADE (25¬∞ rotation, 20% brightness/contrast)"
echo "  - Scheduler: Cosine with 10-epoch warmup"
echo "  - Patience: 22 epochs (allow sufficient learning)"
echo "  - Epochs: 100 (INCREASED from 50 for convergence)"
echo ""

# Train 5-Class with MobileNetV2 (Hybrid Approach)
python3 ensemble_5class_trainer.py \
    --mode train \
    --dataset_path ./dataset_eyepacs_5class_balanced \
    --output_dir ./mobilenet_5class_v2_results \
    --experiment_name "5class_mobilenet_v2_hybrid_384" \
    --base_models mobilenet_v2 \
    --num_classes 5 \
    --img_size 384 \
    --batch_size 16 \
    --epochs 100 \
    --learning_rate 5e-4 \
    --weight_decay 2e-4 \
    --ovo_dropout 0.4 \
    --freeze_weights false \
    --enable_clahe \
    --clahe_clip_limit 2.5 \
    --enable_medical_augmentation \
    --rotation_range 25.0 \
    --brightness_range 0.20 \
    --contrast_range 0.20 \
    --enable_focal_loss \
    --enable_class_weights \
    --class_weight_0 1.0 \
    --class_weight_1 1.0 \
    --class_weight_2 1.0 \
    --class_weight_3 1.0 \
    --class_weight_4 1.0 \
    --focal_loss_alpha 2.5 \
    --focal_loss_gamma 3.0 \
    --label_smoothing 0.10 \
    --scheduler cosine \
    --warmup_epochs 10 \
    --validation_frequency 1 \
    --checkpoint_frequency 5 \
    --patience 22 \
    --early_stopping_patience 17 \
    --target_accuracy 0.92 \
    --max_grad_norm 1.0 \
    --seed 42 \
    --device cuda \
    --no_wandb

echo ""
echo "‚úÖ 5-CLASS MobileNetV2 HYBRID OVO ENSEMBLE training completed!"
echo ""
echo "üìä MOBILENETV2 VERSION COMPARISON:"
echo ""
echo "  Parameter          | v1 (Paper Replica) | v2 (Hybrid Winner) | Change"
echo "  -------------------|--------------------|--------------------|------------------"
echo "  Image Size         | 224√ó224            | 384√ó384            | +87% pixels"
echo "  CLAHE              | ‚ùå Disabled        | ‚úÖ Enabled         | +3-5% accuracy"
echo "  Batch Size         | 32                 | 16                 | -50% (memory)"
echo "  Learning Rate      | 1e-3               | 5e-4               | -50% (stability)"
echo "  Dropout            | 0.5                | 0.4                | -20% (capacity)"
echo "  Label Smoothing    | 0.0                | 0.10               | Medical standard"
echo "  Focal Loss         | ‚ùå Disabled        | ‚úÖ Enabled         | Class balance"
echo "  Weight Decay       | 1e-4               | 2e-4               | +100% (regularize)"
echo "  Epochs             | 50                 | 100                | +100% (converge)"
echo ""
echo "üìà EXPECTED RESULTS (Based on Hybrid Approach):"
echo "  Individual Binary Pairs:"
echo "    ‚Ä¢ Strong pairs (0v3, 0v4): 96-99% (target: match winner's 98%)"
echo "    ‚Ä¢ Good pairs (0v1, 0v2, 1v3, 1v4, 2v4): 90-95% (improved from v1)"
echo "    ‚Ä¢ Weak pairs (1v2, 2v3, 3v4): 85-92% (CLAHE + high-res boost)"
echo "    ‚Ä¢ Average pair accuracy: ~92-94% (vs v1 target: 92%)"
echo "  "
echo "  Final Ensemble Performance:"
echo "    ‚Ä¢ Target accuracy: 92-94% (exceeds medical-grade ‚â•90%)"
echo "    ‚Ä¢ Medical grade: ‚úÖ PASS (if ‚â•90%)"
echo "    ‚Ä¢ Research quality: ‚úÖ EXCELLENT (if ‚â•92%)"
echo ""
echo "‚ö†Ô∏è  CRITICAL SUCCESS METRICS:"
echo "  IF ACCURACY ‚â• 92%:"
echo "    ‚úÖ EXCELLENT! Hybrid approach works perfectly"
echo "    ‚úÖ Proceed to train DenseNet v4 (448√ó448) and EfficientNetB2 v2 (384√ó384)"
echo "    ‚úÖ Train SEResNext (512√ó512) for meta-ensemble"
echo "    ‚úÖ Expected meta-ensemble: 94-96% (medical production grade)"
echo ""
echo "  IF ACCURACY 88-92%:"
echo "    ‚úÖ GOOD! Hybrid approach shows improvement over v1"
echo "    ‚ö†Ô∏è  Consider: Increase resolution to 448√ó448 for MobileNet v3"
echo "    ‚úÖ Still proceed with other models (may perform better)"
echo ""
echo "  IF ACCURACY 85-88%:"
echo "    ‚ö†Ô∏è  MODERATE! Better than v1 paper approach (~85%)"
echo "    üí° Next: Try MobileNet v3 with 448√ó448 or 512√ó512"
echo "    üí° Focus on DenseNet v4 and EfficientNetB2 v2 (better architectures)"
echo ""
echo "  IF ACCURACY < 85%:"
echo "    ‚ùå UNEXPECTED - Similar to v1 failure"
echo "    üí° Check: CLAHE working? Dataset issues? GPU utilization?"
echo "    üí° Try: Increase batch size to 24, reduce resolution to 320√ó320"
echo ""
echo "üìä MONITORING CHECKPOINTS (Expected Progression):"
echo "  Epoch 10:  ~75-80% (warmup complete, CLAHE effect visible)"
echo "  Epoch 25:  ~85-88% (high-res features learned)"
echo "  Epoch 50:  ~90-92% (approaching target)"
echo "  Epoch 75:  ~92-94% (refinement phase)"
echo "  Epoch 100: ~92-94% (final performance)"
echo ""
echo "üîß NEXT STEPS BASED ON RESULTS:"
echo "  1. Analyze results:"
echo "     python3 model_analyzer.py --model ./mobilenet_5class_v2_results/models/"
echo ""
echo "  2. Compare with baselines:"
echo "     - v1 (Paper): Expected ~92%, likely got <85%"
echo "     - v2 (Hybrid): Target 92-94%"
echo "     - DenseNet v3: 64.84% (low res baseline)"
echo "     - EfficientNetB2 v1: 64.20% (low res baseline)"
echo ""
echo "  3. If successful (‚â•88%):"
echo "     bash train_5class_densenet_v4.sh      # 448√ó448 high-res"
echo "     bash train_5class_efficientnetb2_v2.sh # 384√ó384 hybrid"
echo "     bash train_5class_seresnext.sh         # 512√ó512 winner's model"
echo ""
echo "  4. If moderate (85-88%):"
echo "     - Proceed with other models anyway (DenseNet/EfficientNet may perform better)"
echo "     - Consider MobileNet v3 with 448√ó448 or 512√ó512"
echo ""
echo "  5. If unsuccessful (<85%):"
echo "     - Review training logs: tail -f ./mobilenet_5class_v2_results/logs/*.log"
echo "     - Check CLAHE effect: Compare with/without CLAHE samples"
echo "     - Verify GPU memory: nvidia-smi (should use ~14-15GB for batch 16)"
echo ""
echo "üöÄ Training started at: $(date)"
echo "üìÅ Results directory: ./mobilenet_5class_v2_results/"
echo "üìä Monitor progress: tail -f ./mobilenet_5class_v2_results/logs/*.log"
echo ""
echo "üí° CRITICAL REMINDER:"
echo "   This v2 combines:"
echo "   1. Kaggle 1st place winner's higher resolution approach (384√ó384)"
echo "   2. Your research paper's CLAHE preprocessing (+3-5% proven)"
echo "   3. OVO binarization framework (10 binary classifiers)"
echo "   4. Medical-grade focal loss and class weighting"
echo ""
echo "   Expected improvement over v1:"
echo "   - CLAHE: +3-5% absolute gain"
echo "   - Higher resolution: +2-4% absolute gain"
echo "   - Total expected: 92-94% (vs v1 target: 92%)"
echo ""
